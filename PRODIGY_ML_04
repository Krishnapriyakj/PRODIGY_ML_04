!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/


!kaggle datasets download -d roobansappani/hand-gesture-recognition


import zipfile
zip_ref = zipfile.ZipFile('/content/hand-gesture-recognition.zip', 'r')
zip_ref.extractall('/content')
zip_ref.close()


import os

# List files and directories in the root content directory
for root, dirs, files in os.walk('/content'):
    for name in dirs:
        print(os.path.join(root, name))
    for name in files:
        print(os.path.join(root, name))


import cv2
import numpy as np



def load_images_from_directory(data_dir,classes):
  images=[]
  labels=[]
  for label,class_name in enumerate(classes):
    class_dir=os.path.join(data_dir,'images',class_name)
    if not os.path.exists(class_dir):
      print(f"Directory does not exist:{class_dir}")
      continue
    for img_name in os.listdir(class_dir):
      img_path=os.path.join(class_dir,img_name)
      img=cv2.imread(img_path)
      if img is not None:
        img=cv2.resize(img,(128,128))
        images.append(img)
        labels.append(label)
  return np.array(images),np.array(labels)


data_dir='/content/HandGesture'
classes=['call_me', 'fingers_crossed', 'okay', 'paper', 'peace', 'rock', 'rock_on', 'scissor', 'thumbs', 'up']






images, labels = load_images_from_directory(data_dir, classes)
images = images.astype('float32') / 255.0



print(f'Loaded {images.shape[0]} images with shape {images.shape[1:]}')
print(f'Loaded {labels.shape[0]} labels')


from sklearn.model_selection import train_test_split
train_images, val_images, train_labels, val_labels = train_test_split(images, labels, test_size=0.2, random_state=42)


import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt





model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(len(classes), activation='softmax')
])


model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])


datagen=ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True
  )


history=model.fit(
    datagen.flow(train_images,train_labels,batch_size=32),
    validation_data=(val_images,val_labels),
    epochs=20
)



# Plot training & validation accuracy values
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')



# Plot training & validation loss values
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()



val_loss, val_accuracy = model.evaluate(val_images, val_labels, verbose=2)
print(f'Validation accuracy: {val_accuracy:.2f}')



def predict_single_image(img_path, model, classes):
    img = cv2.imread(img_path)
    if img is None:
        raise ValueError(f"Error loading image: {img_path}")
    img = cv2.resize(img, (128, 128))
    img = img.astype('float32') / 255.0
    img = np.expand_dims(img, axis=0)
    prediction = model.predict(img)
    predicted_class = np.argmax(prediction, axis=1)[0]
    return classes[predicted_class]


user_image_path = '/content/1058.jpg'
try:
    predicted_class = predict_single_image(user_image_path, model, classes)
    print(f'Prediction for the user-provided image: {predicted_class}')
except ValueError as e:
    print(e)
